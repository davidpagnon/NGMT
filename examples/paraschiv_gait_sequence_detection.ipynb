{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paraschiv Gait Sequence Detection\n",
    "\n",
    "This example can be referenced by citing the package.\n",
    "\n",
    "The example illustrates how the gait sequence detection algorithm is used to detect gait sequences using body acceleration recorded with a triaxial accelerometer worn or fixed on the lower back. The gait sequence detection algorithm is implemented using [`ngmt.modules.gsd._paraschiv`](https://github.com/neurogeriatricskiel/NGMT/tree/main/ngmt/modules/gsd/_paraschiv.py). This algorithm is based on the research of Paraschiv-Ionescu et al [1-2].\n",
    "\n",
    "The algorithm detects gait sequences based on identified steps. It starts by loading the accelerometer data, which includes three columns corresponding to the acceleration signals across the x, y, and z axes, along with the sampling frequency of the data. To simplify the analysis, the norm of acceleration across the x, y, and z axes is computed. Next, the signal is resampled at a 40 Hz sampling frequency using interpolation. Smoothing is then applied through a Savitzky-Golay filter and a Finite Impulse Response (FIR) low-pass filter to remove noise and drifts from the signal. The continuous wavelet transform is applied to capture gait-related features, followed by additional smoothing using successive Gaussian-weighted filters. The processed data is then analyzed to detect gait sequences.\n",
    "\n",
    "The algorithm continues by identifying the envelope of the processed acceleration signal. Active periods of the signal are identified using the Hilbert envelope. The statistical distribution of the amplitude of the peaks in these active periods is used to derive an adaptive threshold. In case the Hilbert envelope algorithm fails to detect active periods, a fixed threshold value (0.15 g) is used for peak detection in the signal. Mid-swing peaks are detected based on this threshold. Pulse trains in the local maximum and minimum of the peaks are identified, with those having fewer than four steps filtered out. The intersection of pulse trains from local maximum and minimum peaks is detected as walking periods. These periods are then organized and grouped to update the start and end times of detected walking bouts.\n",
    "\n",
    "Next, the algorithm takes the last steps to detect walking bouts in the signal. For this purpose, walking bouts with five or more steps are detected, and their start and end times are added to the list. Walking labels are generated as an array of zeros, and the intervals corresponding to the walking bouts are labeled as 1. Groups of consecutive zeros in the walking labels are identified, and if breaks between walking bouts are less than three seconds, they are merged. The output is then constructed as a DataFrame containing gait sequence information in BIDS format. If gait sequences are found, the output is printed; otherwise, a message indicating that no gait sequences are detected is displayed.\n",
    "\n",
    "[1] Paraschiv-Ionescu et al. (2019). Locomotion and cadence detection using a single trunk-fixed accelerometer:\n",
    "    validity for children with cerebral palsy in daily life-like conditions. Journal of NeuroEngineering and Rehabilitation, 16(1), 24.\n",
    "    https://doi.org/10.1186/s12984-019-0494-z\n",
    "\n",
    "[2] Paraschiv-Ionescu et al. (2020). Real-world speed estimation using single trunk\n",
    "IMU: methodological challenges for impaired gait patterns.\n",
    "    Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society.\n",
    "    https://doi.org/10.1109/EMBC44109.2020.9176281"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "The necessary libraries such as numpy, matplotlib.pyplot, dataset, and gait sequence detection module are imported. Make sure that you have all the required libraries and modules installed before running this code. You also may need to install the 'ngmt' library and its dependencies if you haven't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ngmt.datasets import mobilised\n",
    "from ngmt.modules.gsd import ParaschivIonescuGaitSequenceDetection\n",
    "from ngmt.config import cfg_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "To implement the gait sequence detection algorithm, we load example data from a congestive heart failure (CHF) cohort, which is publicly available on the Zenodo repository [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7547125.svg)](https://doi.org/10.5281/zenodo.7547125). \n",
    "\n",
    "The participant was assessed for 2.5 hours in the real-world while doing different daily life activities and also was asked to perform specific tasks such as outdoor walking, walking up and down a slope and stairs and moving from one room to another [`3`].\n",
    "\n",
    "Since we will use norm of the accleration signal to detect gait sequences, we don't need to take care of orientation of the signal.\n",
    "\n",
    "Refertences\n",
    "\n",
    ".. [`3`] Mazz√†, Claudia, et al. \"Technical validation of real-world monitoring of gait: a multicentric observational study.\" BMJ open 11.12 (2021): e050785. http://dx.doi.org/10.1136/bmjopen-2021-050785\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'file_path' variable holds the absolute path to the data file\n",
    "file_path = (\n",
    "    r\"C:\\Users\\Project\\Desktop\\Gait_Sequence\\Mobilise-D dataset_1-18-2023\\CHF\\data.mat\"\n",
    ")\n",
    "\n",
    "# In this example, we use \"SU\" as tracking_system and \"LowerBack\" as tracked points.\n",
    "tracking_sys = \"SU\"\n",
    "tracked_points = {tracking_sys: [\"LowerBack\"]}\n",
    "\n",
    "# The 'mobilised.load_recording' function is used to load the data from the specified file_path\n",
    "recording = mobilised.load_recording(\n",
    "    file_name=file_path, tracking_systems=[tracking_sys], tracked_points=tracked_points\n",
    ")\n",
    "\n",
    "# Load lower back acceleration data\n",
    "acceleration_data = recording.data[tracking_sys][\n",
    "    [\"LowerBack_ACCEL_x\", \"LowerBack_ACCEL_y\", \"LowerBack_ACCEL_z\"]\n",
    "]\n",
    "\n",
    "# Get the corresponding sampling frequency\n",
    "sampling_frequency = recording.channels[tracking_sys][\n",
    "    recording.channels[tracking_sys][\"name\"] == \"LowerBack_ACCEL_x\"\n",
    "][\"sampling_frequency\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of the Data\n",
    "The raw acceleration data including components of x, y and z axis is represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the time values in minutes\n",
    "# The 'time_in_minute' array represents time values in minutes, computed based on the length of 'acceleration_data' and 'sampling_frequency'.\n",
    "time_in_minute = np.arange(len(acceleration_data)) / (60 * sampling_frequency)\n",
    "\n",
    "# Create a figure with a specified size\n",
    "plt.figure(figsize=(22, 14))\n",
    "\n",
    "# Get colors for raw\n",
    "colors = cfg_colors[\"raw\"]\n",
    "\n",
    "# A loop is used to plot data for each accelerometer axis, applying different colors from the color map.\n",
    "for i in range(3):\n",
    "    plt.plot(\n",
    "        time_in_minute,\n",
    "        acceleration_data[f\"LowerBack_ACCEL_{chr(120 + i)}\"],\n",
    "        color=colors[i],\n",
    "        label=f\"Acc {i + 1}\",\n",
    "    )\n",
    "\n",
    "# Add labels and legends\n",
    "plt.xlabel(\"Time [minute]\", fontsize=20)\n",
    "plt.ylabel(\"Acceleration [g]\", fontsize=20)\n",
    "plt.legend(fontsize=18)\n",
    "\n",
    "# Add a title with a specified font size\n",
    "plt.title(\n",
    "    \"Accelerometer data from lower-back IMU sensor for Congestive Heart Failure (CHF) cohort\",\n",
    "    fontsize=30,\n",
    ")\n",
    "\n",
    "# Customize tick font sizes\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "# Display a grid for reference\n",
    "plt.grid(visible=None, which=\"both\", axis=\"both\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom in on specific time periods in the data, particularly the first 10 seconds, where clear blinks are evident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the time values based on the length of the data\n",
    "num_samples = len(acceleration_data)\n",
    "time_seconds = np.arange(num_samples) / sampling_frequency\n",
    "\n",
    "# Create a figure with the specified size\n",
    "plt.figure(figsize=(22, 14))\n",
    "\n",
    "# Plot acceleration data for each axis with time on the x-axis\n",
    "for i in range(3):\n",
    "    plt.plot(\n",
    "        time_seconds,\n",
    "        acceleration_data[f\"LowerBack_ACCEL_{chr(120 + i)}\"],\n",
    "        color=colors[i],\n",
    "        label=f\"Acc {i + 1}\",\n",
    "    )\n",
    "\n",
    "# Add labels and legends\n",
    "plt.xlabel(\"Time [seconds]\", fontsize=20)\n",
    "plt.ylabel(\"Acceleration [g]\", fontsize=20)\n",
    "plt.legend(fontsize=18)\n",
    "\n",
    "# Add a title\n",
    "plt.title(\n",
    "    \"Accelerometer data from lower-back IMU sensor for Congestive Heart Failure (CHF) cohort\",\n",
    "    fontsize=30,\n",
    ")\n",
    "\n",
    "# Customize font sizes\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "# Set x-axis and y-axis limits for a specific duration (in seconds) and acceleration range\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(-1, 1.5)\n",
    "\n",
    "# Display a grid for reference\n",
    "plt.grid(visible=None, which=\"both\", axis=\"both\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the gait sequence detection algorithm\n",
    "Now, we are running gait sequence detection algorithm (Paraschiv Ionescu) from [`NGMT.ngmt.modules.gsd._paraschiv.ParaschivIonescuGaitSequenceDetection`](https://github.com/neurogeriatricskiel/NGMT/tree/main/ngmt/modules/gsd/_paraschiv.py).  The inputs consist of accelerometer data (N, 3) for the x, y, and z axes, the initial sampling frequency of the data, and a plot option. Optionally, if the plot_results flag is set to True, a visualization plot is generated to display the preprocessed data and the detected gait sequences.\n",
    "\n",
    "The onset is represented with the vertical green line and the grey area represents the duration of gait sequence detected by the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the ParaschivIonescuGaitSequenceDetection class\n",
    "gsd = ParaschivIonescuGaitSequenceDetection(target_sampling_freq_Hz=40)\n",
    "\n",
    "# Call the gait sequence detection using gsd.detect\n",
    "gsd = gsd.detect(\n",
    "    data=acceleration_data, sampling_freq_Hz=sampling_frequency, plot_results=True\n",
    ")\n",
    "\n",
    "# Gait sequences are stored in gait_sequences_ attribute of gsd\n",
    "gait_sequences = gsd.gait_sequences_\n",
    "\n",
    "# Add events to the recording as a dictionary including tracking system and events\n",
    "recording.events = {tracking_sys: gait_sequences}\n",
    "print(recording.events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom in on specific time periods in the raw acceleration data, particularly the first detected gait sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the first detected gait sequence\n",
    "first_gait_sequence = recording.events[tracking_sys].iloc[0]\n",
    "print(\"First gait sequence:\\n\", first_gait_sequence)\n",
    "\n",
    "# Plot the raw data from the lower back\n",
    "fig, ax = plt.subplots(figsize=(22, 14))\n",
    "\n",
    "# Plot the acceleration data\n",
    "for i in range(3):\n",
    "    ax.plot(\n",
    "        time_seconds,\n",
    "        acceleration_data[f\"LowerBack_ACCEL_{chr(120 + i)}\"],\n",
    "        color=colors[i],\n",
    "        label=f\"Acc {i + 1}\",\n",
    "    )\n",
    "\n",
    "# Plot the first element of gait sequences if they exist\n",
    "plt.axvline(first_gait_sequence[\"onset\"], color=\"g\", label=\"Gait onset\")\n",
    "ax.axvspan(\n",
    "    first_gait_sequence[\"onset\"],\n",
    "    first_gait_sequence[\"onset\"] + first_gait_sequence[\"duration\"],\n",
    "    alpha=0.2,\n",
    "    color=\"gray\",\n",
    "    label=\"Gait duration\",\n",
    ")\n",
    "\n",
    "# Customize plot\n",
    "start_limit = first_gait_sequence[\"onset\"] - 1\n",
    "end_limit = first_gait_sequence[\"onset\"] + first_gait_sequence[\"duration\"] + 1\n",
    "ax.set_xlim(start_limit, end_limit)\n",
    "ax.set_ylim(-1, 1.5)\n",
    "ax.set_xlabel(\"Time (seconds)\", fontsize=20)\n",
    "ax.set_ylabel(\"Acceleration (g)\", fontsize=20)\n",
    "ax.legend(loc=\"upper right\", fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ngmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
